---
title: "HDT2-Clustering"
author: "Andres Quinto, Mirka Monzon, Oscar De Leon"
date: "20/02/2022"
output: 
  html_document:
    code_folding: hide
    word_document: default
    pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
datos <- read.csv("movies.csv")
library(hopkins)
```

## Hoja de trabajo no.2 

### Clustering 

1. Haga el preprocesamiento del dataset, explique qué variables no aportan información a la generación de grupos y por qué. Describa con qué variables calculará los grupos.

```{r}
variable <- c("id", "original_title", "originalLanguage", "homePage", "video", "actorsCharacter")
DataFrame.Variables <- data.frame(variable)
print(DataFrame.Variables)
```

Las variables listadas anteriormente, son las variables que considereamos no aportan informacion a la generacion de grupos ya que cada una de ellas tienen caracteristicas propias que no se relacionan con las demas y/o contienen informacion no usable. 


2. Analice la tendencia al agrupamiento usando el estadístico de Hopkings y la VAT (Visual Assessment of cluster Tendency). Discuta sus resultados e impresiones.

Para ello necesitamos normalizar los datos de la db.
Referencia para la funcion de hopkins
https://www.rdocumentation.org/packages/clustertend/versions/1.5/topics/hopkins
```{r}
library(hopkins) #Con esto revisamos el agrupamiento.

datos <- read.csv("movies.csv")

datos<-datos[complete.cases(read.csv("movies.csv")),]
popularity<-datos[,'popularity']
budget<-datos[,'budget']
revenue<-datos[,'revenue']
runtime<-datos[,'runtime']
voteCount<-datos[,'voteCount']
NORMD<-data.frame(popularity,budget,revenue,runtime,voteCount)
Clustering<-scale(NORMD)

hopkins(Clustering)

#Matriz de distancia
DistData<- dist(Clustering)

```
Se puede apreciar que el valor que retorna la funcion de hopkins esta muy alejado de 0.5, es decir los datos recopilados no son aleatorios, dandonos a entender que el agrupamiento se puede facilitar. Para ello utilizaremos y analizaremos de forma grafica los datos.

Referencia a la libreria: https://cloud.r-project.org/web/packages/factoextra/factoextra.pdf
```{r}
library(ggplot2)
library(factoextra) #Paquete que facilita los graficos de clustering
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
fviz_dist(DistData, show_labels = F)

```

3. Determine cuál es el número de grupos a formar más adecuado para los datos que está trabajando. Haga una gráfica de codo y explique la razón de la elección de la cantidad de clústeres con la que trabajará. 

```{r}
wss = 0
for (i in 1:10)
  wss[i] <- sum(kmeans(Clustering[,1:5], centers=i)$withinss)
plot(1:10, wss, type="b", xlab="Numero de Clusters",  ylab="WSS")

```

Basado en el resultado del método de codo, el número de clusters óptimo para analizar los datos es 6.


4. Utilice 3 algoritmos existentes para el agrupamiento. Compare los resultados generados por cada uno.

Agrupamiento por medio de k-means
Referencia de la libreria para k-means; https://cran.r-project.org/web/packages/fpc/fpc.pdf
```{r kmeans, echo=FALSE}
library(fpc)
library(factoextra)
library(ggplot2)
library(cluster)

k<-kmeans(Clustering,3,iter.max =100)
datos$grupo<-k$cluster

plotcluster(Clustering,k$cluster) 
#Establecemos k centroides en el espacio de datos para visualizarlos de la forma correcta
fviz_cluster(k, data = Clustering,geom = "point", ellipse.type = "norm")
#Reubicamos y asignamos estos centroides
SiluetaK<-silhouette(k$cluster,dist(Clustering))
mean(SiluetaK[,3]) 
Kmean<-mean(SiluetaK[,3]) 
#Graficamos la silueta de k - means
plot(SiluetaK, cex.names=.4, col=1:3, border=NA)
```
El resultado es muy cercano a 1, el cual es un resultado deseable.


Cluster jerarquico
Para el cluster jerarquico se agrupan los datos basandose en la distancia que tienen entre si, de forma que los datos dentro de este cluster sean con mayor similitud entre si.

```{r}
library(cluster)
Matrix<- dist(Clustering)
hc<-hclust(DistData, method = "ward.D2") #se genera el cluster jerarquico
plot(hc, cex=0.5, axes=FALSE)#Utilizamos un dendograma
rect.hclust(hc,k=3)

groups<-cutree(hc,k=3) #Determinamos el grupo de cada fila, cortando el grafico
datos$gruposHC<-groups

silhc<-silhouette(groups,DistData)
mean(silhc[,3]) 
Jerarquico<-mean(silhc[,3])

plot(silhc, cex.names=.4, col=1:3, border = NA)
```

Similar al resultado anterior con el cluster jerarquico obtuvimos un resultado deseable, cercano a 1


Mezcla de gaussiano
Esta mezcla determina que todos los datos que se generan conforman una mezcla de distribuciones gaussianas de forma finita.

Referencia a la libreria de agrupamiento: https://cran.r-project.org/web/packages/mclust/index.html
```{r}
library(cluster)
library(mclust)
mclust<-Mclust(Clustering,3)
datos$mxGau<-mclust$classification
silmg<-silhouette(mclust$classification,DistData)
mean(silmg[,3]) 
Gauss<-mean(silmg[,3]) 
plot(silmg, cex.names=.4, col=1:3, border = NA)
```
Podemos observar, que con este algoritmo obtuvimos `r mean(silmg[,3])` de promedio de la silueta, el valor es mas cercano a 0 que a 1, gracias a que posee demasiadas siluetas negativas.

El valor es mas cercano a 0 que a 1, gracias a que posee demasiadas siluetas negativas.

5. Determine la calidad del agrupamiento hecho por cada algoritmo con el método de la silueta. Discuta los resultados. 

k-mean

Como se puede en la grafica realizada con el metodo de la silueta en el inciso anterior, la primera agrupacion se ve coherente, y en la segunda y tercera agrupacion se obtuvieron algunos valores atipicos, pero el coeficiente es bastante cercano a 1 lo que es adecuado.

Cluster jerarquico

Como se puede en la grafica realizada con el metodo de la silueta en el inciso anterior, se puede ver que los clusters involucrados son coherentes en la gran mayoria, solo con algunos datos atipicos.

Mezcla de gaussiano

Como se puede en la grafica realizada con el metodo de la silueta en el inciso anterior, esta grafica se obtuvo un mayor de datos atipicos, casi iguales a los datos 'normales', solo la terccera agrupacion es totalmete coherente y el coeficiente es mas cercano a 0. 

6. Interprete  los  grupos  basado  en  el  conocimiento  que  tiene  de  los  datos.  Recuerde  investigar  las medidas de tendencia central de las variables continuas y las tablas de frecuencia de las variables categóricas pertenecientes a cada grupo. Identifique hallazgos interesantes debido a las agrupaciones y describa para qué le podría servir.


```{r Media popularity}
mean(x = NORMD$popularity, na.rm = TRUE)
```
La media de la popularidad es 68.1854


```{r Media budget}
mean(x = NORMD$budget, na.rm = TRUE)
```
La media de presupuesto es 24335422


```{r Media revenue}
mean(x = NORMD$revenue, na.rm = TRUE)
```

```{r Media runtime}
mean(x = NORMD$runtime, na.rm = TRUE)
```
La media de runtime es de 103.2592


```{r Media VoteCount}
round(mean(x = NORMD$voteCount, na.rm = TRUE))
```
La media de votos es 1871


```{r Moda popularity}
tabla <- table(NORMD$popularity)
head(sort(tabla, decreasing = TRUE), n = 15)
```
La moda de la popularidad es compartida entre 15.804 y 39.372 con 3 repeticiones cada una. 


```{r Moda budget}
tabla <- table(NORMD$budget)
head(sort(tabla, decreasing = TRUE), n = 15)
```
La moda de presupuestos es de 20000000 con 84 repeticiones. El valor 0 ha sido ignorado debido a que se considera un NA o NULL.



```{r Moda revenue}
tabla <- table(NORMD$revenue)
head(sort(tabla, decreasing = TRUE), n = 15)
```
La moda de los infresos es 7e+06 con 3 repeticiones. El valor 0 es ignorado debido a que se considera un NA o NuLL.


```{r Moda runtime}
tabla <- table(NORMD$runtime)
head(sort(tabla, decreasing = TRUE), n = 15)
```
La moda de runtime es 90 con 143 repeticiones. 


```{r Moda VoteCount}
tabla <- table(NORMD$voteCount)
head(sort(tabla, decreasing = TRUE), n = 15)
```
La moda de votos por pelicula es de 4 con 15 repeticiones. 

