---
title: "HDT2-Clustering"
author: "Andres Quinto, Mirka Monzon, Oscar De Leon"
date: "20/02/2022"
output: 
  html_document:
    code_folding: hide
    word_document: default
    pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
datos <- read.csv("movies.csv")
```

## Hoja de trabajo no.2 

### Clustering 

1. Haga el preprocesamiento del dataset, explique qué variables no aportan información a la generación de grupos y por qué. Describa con qué variables calculará los grupos.

```{r}
variable <- c("id", "original_title", "originalLanguage", "homePage", "video", "actorsCharacter")
DataFrame.Variables <- data.frame(variable)
print(DataFrame.Variables)
```

Las variables listadas anteriormente, son las variables que considereamos no aportan informacion a la generecion de grupos ya que cada una de ellas tienen caracteristicas propias que no se relacionan con las demas y/o contienen informacion no usable. 


2. Analice la tendencia al agrupamiento usando el estadístico de Hopkings y la VAT (Visual Assessment of cluster Tendency). Discuta sus resultados e impresiones.

Para ello necesitamos normalizar los datos de la db.
Referencia para la funcion de hopkins
https://www.rdocumentation.org/packages/clustertend/versions/1.5/topics/hopkins
```{r}
library(hopkins) #Con esto revisamos el agrupamiento.

datos <- read.csv("movies.csv")

datos<-datos[complete.cases(read.csv("movies.csv")),]
popularity<-datos[,'popularity']
budget<-datos[,'budget']
revenue<-datos[,'revenue']
runtime<-datos[,'runtime']
voteCount<-datos[,'voteCount']
NORMD<-data.frame(popularity,budget,revenue,runtime,voteCount)
Clustering<-scale(NORMD)

hopkins(Clustering)

#Matriz de distancia
DistData<- dist(Clustering)

```
Se puede apreciar que el valor que retorna la funcion de hopkins esta muy alejado de 0.5, es decir los datos recopilados no son aleatorios, dandonos a entender que el agrupamiento se puede facilitar. Para ello utilizaremos y analizaremos de forma grafica los datos.

Referencia a la libreria: https://cloud.r-project.org/web/packages/factoextra/factoextra.pdf
```{r}
library(factoextra) #Paquete que facilita los graficos de clustering
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
fviz_dist(DistData, show_labels = F)

```

3. Determine cuál es el número de grupos a formar más adecuado para los datos que está trabajando. Haga una gráfica de codo y explique la razón de la elección de la cantidad de clústeres con la que trabajará. 

```{r}
wss = 0
for (i in 1:10)
  wss[i] <- sum(kmeans(NORMD[,1:5], centers=i)$withinss)
plot(1:10, wss, type="b", xlab="Numero de Clusters",  ylab="WSS")

```

Basado en el metodo de codo, la cantidad de clusters optima de clusters puede variar entre 4 y 5.


4. Utilice 3 algoritmos existentes para el agrupamiento. Compare los resultados generados por cada uno.

Agrupamiento por medio de k-means
Referencia de la libreria para k-means; https://cran.r-project.org/web/packages/fpc/fpc.pdf
```{r kmeans, echo=FALSE}
library(fpc)
library(factoextra)

k<-kmeans(Clustering,3,iter.max =100)
datos$grupo<-k$cluster

plotcluster(Clustering,k$cluster) 
```
Cluster jerarquico
Para el cluster jerarquico se agrupan los datos basandose en la distancia que tienen entre si, de forma que los datos dentro de este cluster sean con mayor similitud entre si.

```{r}
Matrix<- dist(Clustering)
hc<-hclust(DistData, method = "ward.D2") #se genera el cluster jerarquico
plot(hc, cex=0.5, axes=FALSE)#Utilizamos un dendograma
rect.hclust(hc,k=3)

groups<-cutree(hc,k=3) #Determinamos el grupo de cada fila, cortando el grafico
datos$gruposHC<-groups

silhc<-silhouette(groups,DistData)
mean(silhc[,3]) 
Jerarquico<-mean(silhc[,3]) 
```
Mezcla de gaussiano
Esta mezcla determina que todos los datos que se generan conforman una mezcla de distribuciones gaussianas de forma finita.

Referencia a la libreria de agrupamiento: https://cran.r-project.org/web/packages/mclust/index.html
```{r}
library(mclust)
mclust<-Mclust(Clustering,3)
datos$mxGau<-mclust$classification
silmg<-silhouette(mclust$classification,datos_dist)
mean(silmg[,3]) 
Gauss<-mean(silmg[,3]) 

```
Podemos observar, que con este algoritmo obtuvimos `r mean(silmg[,3])` de promedio de la silueta, el valor es mas cercano a 0 que a 1, gracias a que posee demasiadas siluetas negativas.

El valor es mas cercano a 0 que a 1, gracias a que posee demasiadas siluetas negativas.

5. Determine la calidad del agrupamiento hecho por cada algoritmo con el método de la silueta. Discuta los resultados. 

```{r}

```

6. Interprete  los  grupos  basado  en  el  conocimiento  que  tiene  de  los  datos.  Recuerde  investigar  las medidas de tendencia central de las variables continuas y las tablas de frecuencia de las variables categóricas pertenecientes a cada grupo. Identifique hallazgos interesantes debido a las agrupaciones y describa para qué le podría servir.

